1. 딥러닝이 발전한 이유
   1. 데이터가 많아짐(빅데이터)
   2. 하드웨어 발전
   3. 알고리즘의 발전(tensorflow)

2. 딥러닝 architecture
   1. 좁은 의미의 DNN
   2. CNN - 이미지 처리
   3. RNN - 시계열 데이터 처리
3. 딥러닝의 활성화함수
   1. sigmoid
   2. ReLU
   3. softmax
   4. selu
4. 딥러닝의 optimizer 에 해당하지 않는 것
   1. adam
   2. SGD
   3. RMSProp
   4. GD
   5. NAG
   6. Momentum
5. CNN의 구성(구현체)
   1. convolution layer
   2. max pooling
   3. fully connected layer
6. RNN의 구현체
   1. simple RNN
   2. LSTM
   3. GRU
7. 데이터 전처리
   1. 넓은 범위의 데이터를 정규화 (scaling)
   2. 결측치 처리
   3. feature selection : 특성 추출
8. overfitting을 줄이는 방법
   1. dropout
   2. 정규화
   3. batch normalization : standard scaler, batch scaler
9. underfitting을 막는 방법
   1. 더 좋은 특성을 제공
   2. parameter가 더 많은 모델 사용
   3. relu func 사용
   4. 제약 감소
10. model. 했을 때 사용할 수 있는 함수, 없는 함수
11. **단답형** 인공지능, ML, DL에 대해 설명
12. **단답형** 데이터 전처리 기법
    1. 데이터 정제, 데이터 통합, 데이터 축소, 데이터 변환
13. **서술형** CNN architecture?
    1. convolution layer와 maxpooling이 반복되다가 마지막 dense층이 반복되는 구조

